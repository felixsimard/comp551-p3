# -*- coding: utf-8 -*-
"""Copy of Tony-Exploration.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/138PcLgBZuLneb-x1rG-80CTU9ellfa3e
"""

# Tony's Notebook for exploring the assignment

"""Followed this video: https://www.youtube.com/watch?v=Jy4wM2X21u0&t=907s
This guy is solid.
"""

import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torch.utils.data import DataLoader, TensorDataset
import torchvision.datasets as datasets
import torchvision.transforms as transforms
import pickle
import matplotlib.pyplot as plt
import string
import math
from tqdm import tqdm  # For nice progress bar!

# Mount drive to get data

# Device configuration
device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
print(device)

"""## The Convolutional Neural Network"""

# Must understand Conv2d to be able to debug/understand this. Will watch lectures soon



# Model number 2. This is simple feedforward, used to just make sure things work.

class NN(nn.Module):
    def __init__(self, input_size, num_classes):
        super(NN, self).__init__()
        self.fc1 = nn.Linear(input_size, 50)
        self.fc2 = nn.Linear(50, num_classes)

    def forward(self, x):
        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        return x

# Implement CONV Net - other conv net
# Must understand Conv2d to be able to debug/understand this. Will watch lectures soon



# Basic Check To see if net makes sense. Something is wrong with my CNN.
# DOn't really understand it yet, but this code below should used to just check if
# the inputs and outputs work.

dummy_model = NN(3136, 36)
random_input = torch.randn(64, 3136)
print(dummy_model(random_input).shape)

"""## Hyper-parameters"""

# Hyper-parameters
input_channels = 3136
num_classes = 36

BATCH_SIZE = 100
LEARNING_RATE = 0.001
NUM_EPOCHS = 4

"""## Load and Show Data"""

alpha_dict = dict(enumerate(string.ascii_lowercase))
print(alpha_dict)

def get_label_value(labels):
  """
  This function will return a string representing the label of a picture given
  the array label as input:
  Ex ouput: '1a', '4z' ...
  """
  label_temp = labels.tolist()
  label_temp = [int(x) for x in label_temp]
  number = label_temp[:10].index(1)
  letter = alpha_dict[label_temp[10:].index(1)]

  return str(number) + str(letter)

def load_data(filepath):
    loaded_pkl = None
    try:
        with open(filepath, 'rb') as pkl_buffered:
            loaded_pkl = pickle.load(pkl_buffered)
        return loaded_pkl
    except Exception as e:
        print("Error loading data: {}".format(e))

train_test_percentage = .3

train_data = load_data("../data/images_l.pkl")
train_labels = load_data("../data/labels_l.pkl")

# Split train into train and test
old_length_train = len(train_data)
old_length_test = len(train_data)

test_data = train_data[:math.floor(old_length_train*.3)]
train_data = train_data[math.floor(old_length_train*.3):]

test_labels = train_labels[:math.floor(old_length_test*.3)]
train_labels = train_labels[math.floor(old_length_test*.3):]

print(train_data.shape)
print(test_data.shape)

# Visualize some data

# figure = plt.figure(figsize=(20, 8))
# cols, rows = 20, 5
# for i in range(1, cols * rows + 1):
#     sample_idx = torch.randint(len(train_data), size=(1,)).item()
#     img = train_data[sample_idx]
#     label = get_label_value(train_labels[sample_idx])
#     figure.add_subplot(rows, cols, i)
#     plt.title(label)
#     plt.axis("off")
#     plt.imshow(img.squeeze())
# plt.show()

# Turn data and labels into a DataLoader
train_loader = DataLoader(TensorDataset(torch.Tensor(train_data),
                                    torch.Tensor(train_labels)), shuffle=True, batch_size=BATCH_SIZE)
test_loader = DataLoader(TensorDataset(torch.Tensor(test_data),
                                    torch.Tensor(test_labels)), shuffle=True, batch_size=BATCH_SIZE)

"""## Define All Classes"""

# Define classes
classes = []
for l in range(26):
    letter_str = [0.0 for i in range(26)]
    letter_str[l] = 1.0
    for d in range(10):
        digits_str = [0.0 for j in range(10)]
        digits_str[d] = 1.0
        c = digits_str + letter_str
        # c = "".join(c_str)
        classes.append(c)
print(len(classes))

"""## Initialize"""

model = NN(input_size=input_channels, num_classes=num_classes).to(device)

criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)

"""## Train"""

# Train Network
for epoch in range(NUM_EPOCHS):
    for batch_idx, (data, targets) in enumerate(tqdm(train_loader)):
        # Get data to cuda if possible
        data = data.to(device=device)
        targets = targets.to(device=device)

        # Get to correct shape
        data = data.reshape(data.shape[0], -1)

        # forward
        scores = model(data)
        loss = criterion(scores, targets)

        # backward
        optimizer.zero_grad()
        loss.backward()

        # gradient descent or adam step
        optimizer.step()

"""## Test"""

def transform_output(scores):
    """
    Input a Tensor and output will be another Tensor with same dimension but with all elements 0 except two.
    Those 2 elements will have value of 1 and will correspond to the models prediction about which letter and number
    is in the image.
    :param scores:
    :return:
    """
    return_array = []
    score_list = scores.tolist()

    for score in score_list:
        numbers = score[:10]
        letters = score[10:]
        test = lambda x, max_value : 1 if x >= max_value else 0

        new_numbers = [test(x, max(numbers)) for x in numbers]
        new_letters = [test(x, max(letters)) for x in letters]

        return_array.append(new_numbers + new_letters)

    return torch.Tensor(return_array)

# Check accuracy on training & test to see how good our model
def get_accuracy(loader, model):
    num_correct = 0
    num_samples = 0
    model.eval()

    with torch.no_grad():
        for x, y in loader:
            x = x.to(device=device)
            y = y.to(device=device)
            x = x.reshape(x.shape[0], -1)

            scores = model(x)

            predictions = transform_output(scores)

            temp = (predictions == y)
            results = [all(el) for el in temp]

            num_correct += sum(results)
            num_samples += predictions.size(0)

    model.train()
    return num_correct / num_samples

# This actually runs the tests on train and test set.

print(f"Accuracy on training set: {get_accuracy(train_loader, model) * 100:.2f}%")
print(f"Accuracy on test set: {get_accuracy(test_loader, model) * 100:.2f}%")

"""## Save Predictions to CSV"""

# Will most likely incorporate this into get_accuracy function.
# TODO: make get_acuracy function return an array where the first element is acuracyt and second is the predictions.
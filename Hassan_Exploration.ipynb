{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hassan_Exploration.ipynb",
      "provenance": [],
      "mount_file_id": "1PSxie5U7EJ6OA6Sp7zWWm78HCNeW82kb",
      "authorship_tag": "ABX9TyM+L8aJUGSivPqZdoUWTHOf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/felixsimard/comp551-p3/blob/main/Hassan_Exploration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ojQ-VPtEH2C"
      },
      "source": [
        "import pickle\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
        "from google.colab import drive\n",
        "from sklearn import preprocessing\n",
        "from PIL import Image\n",
        "from typing import List\n",
        "from datetime import datetime"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcUNnH2F0-Ji",
        "outputId": "3b05e481-55f1-4edb-a0d6-ab85638112df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Device configuration\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zw1G23aC1a13"
      },
      "source": [
        "## Utility Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5JUILhN2hJ0"
      },
      "source": [
        "* Displays an image given a bit-based input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAE0dPe-1fdj"
      },
      "source": [
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(img)\n",
        "    # plt.imshow(np.transpose(npimg, (1, 2, 0))) \n",
        "    plt.show()"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6LLTMkP2qZx"
      },
      "source": [
        "* Class to create datasets with correct dimensionality properties, retreived from StackOverflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkFH277n1kNp"
      },
      "source": [
        "# Reference: https://stackoverflow.com/questions/44429199/how-to-load-a-list-of-numpy-arrays-to-pytorch-dataset-loader\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, data, targets, transform=None):\n",
        "        self.data = data\n",
        "        self.targets = torch.LongTensor(targets)\n",
        "        self.transform = transform\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        x = self.data[index]\n",
        "        y = self.targets[index]\n",
        "        \n",
        "        if self.transform:\n",
        "            x = Image.fromarray(self.data[index].astype(np.uint8).transpose(1,2,0))\n",
        "            x = self.transform(x)\n",
        "        \n",
        "        return x, y\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDY2DCoj20_U"
      },
      "source": [
        "* Export a CSV file in the parent directory given a pandas dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNA676-J1pKQ"
      },
      "source": [
        "def makeMyCSV(dataf: pd.DataFrame)->None:\n",
        "  filename = 'kaggle_g19_{}.csv'.format(datetime.now())\n",
        "  dataf.to_csv(filename, sep=',', float_format='{:36}', index=False)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1M2n5aro1_wy"
      },
      "source": [
        "# Felix's load data fn\n",
        "# Function to return pickle loaded file in an ndarray\n",
        "def load_data(filename, data_path='/content/drive/MyDrive/data/'):\n",
        "    drive.mount(\"/content/drive\")\n",
        "    loaded_pkl = None\n",
        "    try:\n",
        "        pkl_buffered = open(data_path+''+filename,'rb')\n",
        "        loaded_pkl = pickle.load(pkl_buffered)\n",
        "    except Exception as e:\n",
        "        print(\"Error loading data: {}\".format(e))\n",
        "    return loaded_pkl"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlW81ckJ2QzT"
      },
      "source": [
        "def get_label_value(labels):\n",
        "  \"\"\"\n",
        "  This function will return a string representing the label of a picture given\n",
        "  the array label as input:\n",
        "  Ex ouput: '1a', '4z' ...\n",
        "  \"\"\"\n",
        "  label_temp = labels.tolist()\n",
        "  label_temp = [int(x) for x in label_temp]\n",
        "  number = label_temp[:10].index(1)\n",
        "  letter = alpha_dict[label_temp[10:].index(1)]\n",
        "\n",
        "  return str(number) + str(letter)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTtNy1VV2UKT"
      },
      "source": [
        "def transform_output(scores):\n",
        "    \"\"\"\n",
        "    Input a Tensor and output will be another Tensor with same dimension but with all elements 0 except two.\n",
        "    Those 2 elements will have value of 1 and will correspond to the models prediction about which letter and number\n",
        "    is in the image.\n",
        "    :param scores:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    return_array = []\n",
        "    score_list = scores.tolist()\n",
        "\n",
        "    for score in score_list:\n",
        "        numbers = score[:10]\n",
        "        letters = score[10:]\n",
        "        test = lambda x, max_value : 1 if x >= max_value else 0\n",
        "\n",
        "        new_numbers = [test(x, max(numbers)) for x in numbers]\n",
        "        new_letters = [test(x, max(letters)) for x in letters]\n",
        "\n",
        "        return_array.append(new_numbers + new_letters)\n",
        "\n",
        "    return return_array"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LlmPTd1MhvSP"
      },
      "source": [
        "## Pickle Data to Numpy NDArray"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQW7faTuIUvF",
        "outputId": "2a18d0df-5ccf-44e8-bfc8-215031810337"
      },
      "source": [
        "# loading all data\n",
        "train_features = load_data(\"images_l.pkl\")[:, None]\n",
        "train_labels = load_data(\"labels_l.pkl\")\n",
        "test = load_data(\"images_test.pkl\")[:, None]\n",
        "train_unlabelled = load_data(\"images_ul.pkl\")[:, None]"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ilsd5Pq9JKvR",
        "outputId": "e682bc8f-c0d9-4ab2-97ca-1bdbe9c1f533"
      },
      "source": [
        "print(train_features.shape, train_features[:1])\n",
        "print(train_labels.shape, train_labels[:1])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(30000, 56, 56) [[[  0.   0.   0. ... 175.   0.   0.]\n",
            "  [  0.   0.   0. ...   0.   0.   0.]\n",
            "  [  0.   0.   0. ...   0. 175.   0.]\n",
            "  ...\n",
            "  [  0.   0.   0. ...   0.   0.   0.]\n",
            "  [  0.   0.   0. ...   0.   0.   0.]\n",
            "  [  0.   0.   0. ...   0.   0.   0.]]]\n",
            "(30000, 36) [[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnMeMk82d3-r"
      },
      "source": [
        "- `train_features` has 30,000 samples of 56x56 images\n",
        "- `train_labels` labels of the 56x56 images, a 36-bit binary vector\n",
        "- The code block below verifies the image data are all in numpy n-dimensional arrays, `np.ndarray`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRmXhhEyf-71",
        "outputId": "bd31b7a0-17f7-4262-e77b-c181fc77a0ce"
      },
      "source": [
        "for data in [train_features, train_labels, train_unlabelled, test]:  \n",
        "  print(type(data) is np.ndarray)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "True\n",
            "True\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "du32maX_5WBs"
      },
      "source": [
        "## Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePlviMIE5c7F"
      },
      "source": [
        "epochs = 50\n",
        "batch = 16\n",
        "lr = 0.002             # learning rate\n",
        "channels = 1           # Image input channel\n",
        "train_test_split = 0.3 # 70% training data, 30% validation data\n",
        "flatten_dim = 56 * 56  # image dim = 56 x 56 px"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R33l2H6jI6jx"
      },
      "source": [
        "## Training & Validation Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DosyNmadK-Rk",
        "outputId": "bc2410e9-c733-4825-cf68-fece016cf6a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        }
      },
      "source": [
        "split_index = math.floor(len(train_labels)*train_test_split)\n",
        "\n",
        "full_train_l = train_features\n",
        "val_l = train_features[:split_index]\n",
        "train_features = train_features[split_index:]\n",
        "\n",
        "full_train_labels_l = train_labels_l\n",
        "val_labels_l = train_labels_l[:split_index]\n",
        "train_labels_l = train_labels_l[split_index:]\n",
        "\n",
        "# DataLoaders\n",
        "full_train_l_dataloader = DataLoader(MyDataset(,, transform=Transform), shuffle=True, batch_size=batch)\n",
        "train_l_dataloader = DataLoader(MyDataset(train_l, train_labels_l, transform=transform), shuffle=True, batch_size=BATCH_SIZE)\n",
        "val_l_dataloader = DataLoader(MyDataset(val_l, val_labels_l, transform=transform), shuffle=True)\n",
        "\n",
        "# Test set for Kaggle\n",
        "test_labels_ul = np.zeros(len(test_ul))\n",
        "test_ul_dataloader = DataLoader(MyDataset(test_ul, test_labels_ul, transform=transform), batch_size=BATCH_SIZE, shuffle=False)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-49-2af036114c45>\"\u001b[0;36m, line \u001b[0;32m12\u001b[0m\n\u001b[0;31m    full_train_l_dataloader = DataLoader(MyDataset(,, transform=Transform), shuffle=True, batch_size=batch)\u001b[0m\n\u001b[0m                                                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQUwa6owksmq"
      },
      "source": [
        "## Tensor DataLoader & Feature Labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUdEUc1t6KJU"
      },
      "source": [
        "# Data transformation parameters\n",
        "mean = (0.5,)\n",
        "std = (0.5,)\n",
        "Transform = transforms.Compose([transforms.Normalize(mean=mean, std=std)])"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkylO2dBofPg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e6f7c03-4c10-4513-eae5-4c18515a60d0"
      },
      "source": [
        "train_labels = train_labels.tolist()\n",
        "# Transforming the numpy arrays into tensors with the labels\n",
        "# Concatenating datasets to have Tensor([[image_features], label])\n",
        "training = DataLoader(TensorDataset(torch.Tensor(train_features).unsqueeze(1),\n",
        "                                    torch.Tensor(train_labels).unsqueeze(1)), batch_size=batch, shuffle=False)\n",
        "\n",
        "test_labels = torch.Tensor(np.zeros(len(test)))\n",
        "testing = DataLoader(TensorDataset(torch.Tensor(test), test_labels))\n",
        "\n",
        "print(len(training)*batch,len(testing))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30000 15000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXd9nIYEsZco"
      },
      "source": [
        "- The classification task calls for classifying an image that contains:\n",
        "1. Characters `A-Z` OR `a-z`\n",
        "2. Numbers `0-9`\n",
        "- Each image will include any combination of 1 lower OR uppercase character and one number\n",
        "- Therefore, the labels will have to include every combination of these characters and numbers:\n",
        "1. 260 different classes: `0-9` AND `A-Z`\n",
        "2. 260 different classes: `0-9` AND `a-z`\n",
        "- A total of 520 `labels`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwywA9w9iQ7y"
      },
      "source": [
        "## Conv. NN Class (Implementation of VGG11 Deep CNN)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2psXaEpiU2T"
      },
      "source": [
        "class CNN(nn.Module):\n",
        "\n",
        "  # Constructor\n",
        "  def __init__(self, in_channels=1, num_classes=36):\n",
        "    super(CNN, self).__init__()         # Access methods in parent class\n",
        "    self.in_channels = in_channels\n",
        "    self.num_classes = num_classes\n",
        "    # convolutional layers \n",
        "    self.conv_layers = nn.Sequential(\n",
        "      nn.Conv2d(self.in_channels, 64, kernel_size=3, padding=1),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "      nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "      nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "      nn.ReLU(),\n",
        "      nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "      nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
        "      nn.ReLU(),\n",
        "      nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "      nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "      nn.ReLU(),\n",
        "      nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "      )\n",
        "        # fully connected linear layers\n",
        "    self.linear_layers = nn.Sequential(\n",
        "      nn.Linear(in_features=512, out_features=4096),\n",
        "      nn.ReLU(),\n",
        "      nn.Dropout2d(0.5),\n",
        "      nn.Linear(in_features=4096, out_features=4096),\n",
        "      nn.ReLU(),\n",
        "      nn.Dropout2d(0.5),\n",
        "      nn.Linear(in_features=4096, out_features=self.num_classes)\n",
        "      )\n",
        "    \n",
        "  def forward(self, x):\n",
        "      x = self.conv_layers(x)\n",
        "      # flatten to prepare for the fully connected layers\n",
        "      x = x.view(x.size(0),-1)\n",
        "      x = self.linear_layers(x)\n",
        "      return x\n",
        "  "
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szvWO_fnGEwh"
      },
      "source": [
        "# Model Loss, Optimization, & Run with CUDA\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vbYaFIBFx-k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "415f6905-72e5-4cac-92ea-908e7f707fc7"
      },
      "source": [
        "model = CNN().to(device)\n",
        "criterion = nn.MultiMarginLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "steps = len(training)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "rxKqEp_BTS3N",
        "outputId": "46350726-1bb1-4ca2-de9f-2cd166d77de6"
      },
      "source": [
        "for epoch in range(epochs):\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(training, 0):\n",
        "        inputs, labels = data[0].to(device), data[1].squeeze_().long().to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        if (i+1) % 100 == 0: # print every 1000 mini-batches\n",
        "            print(f'Epoch [{epoch+1}/ {epochs}], Step [{i+1}/{len(training)}], {running_loss/2000}')\n",
        "            running_loss=0\n",
        "        \n",
        "torch.save(model.state_dict(), './cnn.pth')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-b823b79caeec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1340\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1341\u001b[0m         return F.multi_margin_loss(input, target, p=self.p, margin=self.margin,\n\u001b[0;32m-> 1342\u001b[0;31m                                    weight=self.weight, reduction=self.reduction)\n\u001b[0m\u001b[1;32m   1343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmulti_margin_loss\u001b[0;34m(input, target, p, margin, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3325\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"weight must be one-dimensional\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3327\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulti_margin_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmargin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction_enum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: inconsistent target size, got: [16, 36]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2h5Dzgct_vp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "daa02ab1-3b09-4132-ea4f-34632f8ade67"
      },
      "source": [
        "df = pd.DataFrame(columns=['# Id', 'Category'])\n",
        "#device = torch.device('cpu')\n",
        "with torch.no_grad():\n",
        "  i=0\n",
        "  for data in testing:\n",
        "    images,labels = data\n",
        "    images = data[0].to(device)[None, :]\n",
        "    images = images.permute(1,0,2, 3)\n",
        "    outputs = model(images)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    label_predicted = labels_encoder.inverse_transform(predicted.cpu().numpy())\n",
        "    prediction = str(label_predicted[0])\n",
        "    df.loc[i] = [i, prediction]\n",
        "    i += 1\n",
        "\n",
        "df = df.iloc[:15001]\n",
        "\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th># Id</th>\n",
              "      <th>Category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>000001000000010000000000000000000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>000000000100000000000010000000000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>001000000000000000000100000000000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>000100000000000000000000000000000010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>001000000000000000000100000000000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14995</th>\n",
              "      <td>14995</td>\n",
              "      <td>000000000110000000000000000000000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14996</th>\n",
              "      <td>14996</td>\n",
              "      <td>000100000000000000000000000000000001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14997</th>\n",
              "      <td>14997</td>\n",
              "      <td>000000001000000000000001000000000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14998</th>\n",
              "      <td>14998</td>\n",
              "      <td>000100000000000000000000000000000001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14999</th>\n",
              "      <td>14999</td>\n",
              "      <td>010000000000000000000000000000010000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>15000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        # Id                              Category\n",
              "0          0  000001000000010000000000000000000000\n",
              "1          1  000000000100000000000010000000000000\n",
              "2          2  001000000000000000000100000000000000\n",
              "3          3  000100000000000000000000000000000010\n",
              "4          4  001000000000000000000100000000000000\n",
              "...      ...                                   ...\n",
              "14995  14995  000000000110000000000000000000000000\n",
              "14996  14996  000100000000000000000000000000000001\n",
              "14997  14997  000000001000000000000001000000000000\n",
              "14998  14998  000100000000000000000000000000000001\n",
              "14999  14999  010000000000000000000000000000010000\n",
              "\n",
              "[15000 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    }
  ]
}
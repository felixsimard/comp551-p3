{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hassan_Exploration.ipynb",
      "provenance": [],
      "mount_file_id": "1PSxie5U7EJ6OA6Sp7zWWm78HCNeW82kb",
      "authorship_tag": "ABX9TyM+zu6JlSK0Ue+axxHIYkpY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/felixsimard/comp551-p3/blob/main/Hassan_Exploration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgX1RFRDD5oV"
      },
      "source": [
        "- Notebook to build CNN image classifier\n",
        "- Based on https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#training-on-gpu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ojQ-VPtEH2C"
      },
      "source": [
        "import pickle\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from google.colab import drive\n",
        "from sklearn import preprocessing\n",
        "from PIL import Image\n",
        "from typing import List"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LlmPTd1MhvSP"
      },
      "source": [
        "## Pickle Data to Numpy NDArray"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4pSpno3Fdvb"
      },
      "source": [
        "# Felix's load data fn\n",
        "# Function to return pickle loaded file in an ndarray\n",
        "def load_data(filename, data_path='/content/drive/MyDrive/data/'):\n",
        "    drive.mount(\"/content/drive\")\n",
        "    loaded_pkl = None\n",
        "    try:\n",
        "        pkl_buffered = open(data_path+''+filename,'rb')\n",
        "        loaded_pkl = pickle.load(pkl_buffered)\n",
        "    except Exception as e:\n",
        "        print(\"Error loading data: {}\".format(e))\n",
        "    return loaded_pkl"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQW7faTuIUvF",
        "outputId": "0714b225-a4a7-4e7f-fe08-e0492de73ac2"
      },
      "source": [
        "# loading all data\n",
        "train_features = load_data(\"images_l.pkl\")\n",
        "train_labels = load_data(\"labels_l.pkl\")\n",
        "test = load_data(\"images_test.pkl\")\n",
        "train_unlabelled = load_data(\"images_ul.pkl\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ilsd5Pq9JKvR",
        "outputId": "69e5a590-f976-483b-9d89-ae86b284743e"
      },
      "source": [
        "print(train_features.shape, train_features[:1])\n",
        "print(train_labels.shape, train_labels[:1])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(30000, 56, 56) [[[  0.   0.   0. ... 175.   0.   0.]\n",
            "  [  0.   0.   0. ...   0.   0.   0.]\n",
            "  [  0.   0.   0. ...   0. 175.   0.]\n",
            "  ...\n",
            "  [  0.   0.   0. ...   0.   0.   0.]\n",
            "  [  0.   0.   0. ...   0.   0.   0.]\n",
            "  [  0.   0.   0. ...   0.   0.   0.]]]\n",
            "(30000, 36) [[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnMeMk82d3-r"
      },
      "source": [
        "- `train_features` has 30,000 samples of 56x56 images\n",
        "- `train_labels` labels of the 56x56 images, a 36-bit binary vector\n",
        "- The code block below verifies the image data are all in numpy n-dimensional arrays, `np.ndarray`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRmXhhEyf-71",
        "outputId": "9bbadb68-67e0-4048-a539-279412b2a083"
      },
      "source": [
        "for data in [train_features, train_labels, train_unlabelled, test]:  \n",
        "  print(type(data) is np.ndarray)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "True\n",
            "True\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQUwa6owksmq"
      },
      "source": [
        "## Tensor DataLoader & Feature Labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkylO2dBofPg",
        "outputId": "81ad9256-bf7b-449c-8d31-160950890517",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def labelize(lst):\n",
        "  bin_str = \"\".join(str(int(i)) for i in lst)\n",
        "  return bin_str\n",
        "\n",
        "labels_l_lst = train_labels.tolist()\n",
        "labels_l_lst = [labelize(lst) for lst in labels_l_lst]\n",
        "labels_encoder = preprocessing.LabelEncoder()\n",
        "targets = labels_encoder.fit_transform(labels_l_lst)\n",
        "labels_l_tensor = torch.as_tensor(targets)\n",
        "test_labels = torch.Tensor(np.zeros(len(test)))\n",
        "\n",
        "# Transforming the numpy arrays into tensors with the labels\n",
        "# Concatenating datasets to have Tensor([[image_features], label])\n",
        "training = DataLoader(TensorDataset(torch.Tensor(train_features).unsqueeze(1),\n",
        "                                    labels_l_tensor.unsqueeze(1)), batch_size=batch, shuffle=False)\n",
        "\n",
        "testing = DataLoader(TensorDataset(torch.Tensor(test), test_labels))\n",
        "\n",
        "print(len(testing))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXd9nIYEsZco"
      },
      "source": [
        "- The classification task calls for classifying an image that contains:\n",
        "1. Characters `A-Z` OR `a-z`\n",
        "2. Numbers `0-9`\n",
        "- Each image will include any combination of 1 lower OR uppercase character and one number\n",
        "- Therefore, the labels will have to include every combination of these characters and numbers:\n",
        "1. 260 different classes: `0-9` AND `A-Z`\n",
        "2. 260 different classes: `0-9` AND `a-z`\n",
        "- A total of 520 `labels`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJxJe91NtFqv",
        "outputId": "7311b636-acac-45a9-d2dd-8cf4276fc163"
      },
      "source": [
        "labels = []\n",
        "\n",
        "# This implementation is from Felix\n",
        "for l in range(26):\n",
        "    lowerC, upperC = [0.0 for i in range(26)], [0.0 for i in range(26)] \n",
        "    lowerC[l], upperC[l] = 1.0, 1.0\n",
        "    for d in range(10):\n",
        "        digits_str = [0.0 for j in range(10)]\n",
        "        digits_str[d] = 1.0\n",
        "        Lc = lowerC + digits_str\n",
        "        Uc = upperC + digits_str\n",
        "        labels.append(Lc)\n",
        "        labels.append(Uc)\n",
        "\n",
        "print(labels[:3], len(labels))\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]] 520\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwywA9w9iQ7y"
      },
      "source": [
        "## Conv. NN Class (Implementation of VGG11 Deep CNN)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2psXaEpiU2T"
      },
      "source": [
        "class CNN(nn.Module):\n",
        "\n",
        "  # Constructor\n",
        "  def __init__(self, in_channels=1, num_classes=520):\n",
        "    super(CNN, self).__init__()         # Access methods in parent class\n",
        "    self.in_channels = in_channels\n",
        "    self.num_classes = num_classes\n",
        "    # convolutional layers \n",
        "    self.conv_layers = nn.Sequential(\n",
        "      nn.Conv2d(self.in_channels, 64, kernel_size=3, padding=1),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "      nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "      nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "      nn.ReLU(),\n",
        "      nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "      nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
        "      nn.ReLU(),\n",
        "      nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "      nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "      nn.ReLU(),\n",
        "      nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "      )\n",
        "        # fully connected linear layers\n",
        "    self.linear_layers = nn.Sequential(\n",
        "      nn.Linear(in_features=512, out_features=4096),\n",
        "      nn.ReLU(),\n",
        "      nn.Dropout2d(0.5),\n",
        "      nn.Linear(in_features=4096, out_features=4096),\n",
        "      nn.ReLU(),\n",
        "      nn.Dropout2d(0.5),\n",
        "      nn.Linear(in_features=4096, out_features=self.num_classes)\n",
        "      )\n",
        "    \n",
        "  def forward(self, x):\n",
        "      x = self.conv_layers(x)\n",
        "      # flatten to prepare for the fully connected layers\n",
        "      x = x.view(x.size(0),-1)\n",
        "      x = self.linear_layers(x)\n",
        "      return x\n",
        "  "
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szvWO_fnGEwh"
      },
      "source": [
        "# Model Loss, Optimization, & Run with CUDA\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqMYvDABJco_"
      },
      "source": [
        "epochs = 50\n",
        "batch = 16\n",
        "lr = 0.002"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vbYaFIBFx-k",
        "outputId": "3f67a74b-12ea-454b-e835-6cf6f6b15e16",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Device configuration\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "model = CNN().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "steps = len(training)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rxKqEp_BTS3N",
        "outputId": "407de525-035a-437b-8a95-f865e4412cb8"
      },
      "source": [
        "for epoch in range(epochs):\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(training, 0):\n",
        "        inputs, labels = data[0].to(device), data[1].squeeze_().to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        if (i+1) % 100 == 0: # print every 1000 mini-batches\n",
        "            print(f'Epoch [{epoch+1}/ {epochs}], Step [{i+1}/{len(training)}], {running_loss/2000}')\n",
        "            running_loss=0\n",
        "        \n",
        "torch.save(model.state_dict(), './cnn.pth')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/ 50], Step [100/1875], 0.3126513919830322\n",
            "Epoch [1/ 50], Step [200/1875], 0.31229656624794006\n",
            "Epoch [1/ 50], Step [300/1875], 0.31187915086746215\n",
            "Epoch [1/ 50], Step [400/1875], 0.3101359486579895\n",
            "Epoch [1/ 50], Step [500/1875], 0.30285983443260195\n",
            "Epoch [1/ 50], Step [600/1875], 0.29590328884124756\n",
            "Epoch [1/ 50], Step [700/1875], 0.29334176087379454\n",
            "Epoch [1/ 50], Step [800/1875], 0.2916294112205505\n",
            "Epoch [1/ 50], Step [900/1875], 0.28931315088272097\n",
            "Epoch [1/ 50], Step [1000/1875], 0.2883018696308136\n",
            "Epoch [1/ 50], Step [1100/1875], 0.28757816743850706\n",
            "Epoch [1/ 50], Step [1200/1875], 0.2870291614532471\n",
            "Epoch [1/ 50], Step [1300/1875], 0.2868439402580261\n",
            "Epoch [1/ 50], Step [1400/1875], 0.2853914976119995\n",
            "Epoch [1/ 50], Step [1500/1875], 0.286179443359375\n",
            "Epoch [1/ 50], Step [1600/1875], 0.28502065062522886\n",
            "Epoch [1/ 50], Step [1700/1875], 0.2844630932807922\n",
            "Epoch [1/ 50], Step [1800/1875], 0.2841989665031433\n",
            "Epoch [2/ 50], Step [100/1875], 0.283203179359436\n",
            "Epoch [2/ 50], Step [200/1875], 0.2841158940792084\n",
            "Epoch [2/ 50], Step [300/1875], 0.2844965324401855\n",
            "Epoch [2/ 50], Step [400/1875], 0.28419540452957154\n",
            "Epoch [2/ 50], Step [500/1875], 0.28199312567710877\n",
            "Epoch [2/ 50], Step [600/1875], 0.2824964120388031\n",
            "Epoch [2/ 50], Step [700/1875], 0.2824563443660736\n",
            "Epoch [2/ 50], Step [800/1875], 0.2817808585166931\n",
            "Epoch [2/ 50], Step [900/1875], 0.280633273601532\n",
            "Epoch [2/ 50], Step [1000/1875], 0.2788506398200989\n",
            "Epoch [2/ 50], Step [1100/1875], 0.27646177864074706\n",
            "Epoch [2/ 50], Step [1200/1875], 0.27530811977386477\n",
            "Epoch [2/ 50], Step [1300/1875], 0.26983544731140136\n",
            "Epoch [2/ 50], Step [1400/1875], 0.2641533076763153\n",
            "Epoch [2/ 50], Step [1500/1875], 0.26208921098709104\n",
            "Epoch [2/ 50], Step [1600/1875], 0.25992484402656557\n",
            "Epoch [2/ 50], Step [1700/1875], 0.2560508291721344\n",
            "Epoch [2/ 50], Step [1800/1875], 0.25649723219871523\n",
            "Epoch [3/ 50], Step [100/1875], 0.25509930777549744\n",
            "Epoch [3/ 50], Step [200/1875], 0.25441991662979124\n",
            "Epoch [3/ 50], Step [300/1875], 0.25397874903678896\n",
            "Epoch [3/ 50], Step [400/1875], 0.2508921024799347\n",
            "Epoch [3/ 50], Step [500/1875], 0.25095649337768555\n",
            "Epoch [3/ 50], Step [600/1875], 0.2509917466640472\n",
            "Epoch [3/ 50], Step [700/1875], 0.2480507047176361\n",
            "Epoch [3/ 50], Step [800/1875], 0.24709975385665894\n",
            "Epoch [3/ 50], Step [900/1875], 0.2471953032016754\n",
            "Epoch [3/ 50], Step [1000/1875], 0.24492995429039002\n",
            "Epoch [3/ 50], Step [1100/1875], 0.2453773810863495\n",
            "Epoch [3/ 50], Step [1200/1875], 0.24390996217727662\n",
            "Epoch [3/ 50], Step [1300/1875], 0.244426114320755\n",
            "Epoch [3/ 50], Step [1400/1875], 0.24228307914733888\n",
            "Epoch [3/ 50], Step [1500/1875], 0.24188685584068298\n",
            "Epoch [3/ 50], Step [1600/1875], 0.24003507018089296\n",
            "Epoch [3/ 50], Step [1700/1875], 0.23881564354896545\n",
            "Epoch [3/ 50], Step [1800/1875], 0.23698809385299682\n",
            "Epoch [4/ 50], Step [100/1875], 0.23521750283241272\n",
            "Epoch [4/ 50], Step [200/1875], 0.2346395208835602\n",
            "Epoch [4/ 50], Step [300/1875], 0.23239363193511964\n",
            "Epoch [4/ 50], Step [400/1875], 0.23059136295318602\n",
            "Epoch [4/ 50], Step [500/1875], 0.23121486592292786\n",
            "Epoch [4/ 50], Step [600/1875], 0.23153230953216553\n",
            "Epoch [4/ 50], Step [700/1875], 0.2282820086479187\n",
            "Epoch [4/ 50], Step [800/1875], 0.22795552706718444\n",
            "Epoch [4/ 50], Step [900/1875], 0.22730478501319884\n",
            "Epoch [4/ 50], Step [1000/1875], 0.22695902132987977\n",
            "Epoch [4/ 50], Step [1100/1875], 0.22559405064582824\n",
            "Epoch [4/ 50], Step [1200/1875], 0.22544919538497926\n",
            "Epoch [4/ 50], Step [1300/1875], 0.22480151891708375\n",
            "Epoch [4/ 50], Step [1400/1875], 0.22269618701934815\n",
            "Epoch [4/ 50], Step [1500/1875], 0.22266264867782593\n",
            "Epoch [4/ 50], Step [1600/1875], 0.2223137893676758\n",
            "Epoch [4/ 50], Step [1700/1875], 0.2201484203338623\n",
            "Epoch [4/ 50], Step [1800/1875], 0.21990539073944093\n",
            "Epoch [5/ 50], Step [100/1875], 0.21922185516357423\n",
            "Epoch [5/ 50], Step [200/1875], 0.21902690136432648\n",
            "Epoch [5/ 50], Step [300/1875], 0.2176575495004654\n",
            "Epoch [5/ 50], Step [400/1875], 0.21749473643302916\n",
            "Epoch [5/ 50], Step [500/1875], 0.21666020274162293\n",
            "Epoch [5/ 50], Step [600/1875], 0.21667734932899474\n",
            "Epoch [5/ 50], Step [700/1875], 0.21500910592079162\n",
            "Epoch [5/ 50], Step [800/1875], 0.2150002064704895\n",
            "Epoch [5/ 50], Step [900/1875], 0.2146908425092697\n",
            "Epoch [5/ 50], Step [1000/1875], 0.2147155122756958\n",
            "Epoch [5/ 50], Step [1100/1875], 0.2147808848619461\n",
            "Epoch [5/ 50], Step [1200/1875], 0.2113051859140396\n",
            "Epoch [5/ 50], Step [1300/1875], 0.21361872684955596\n",
            "Epoch [5/ 50], Step [1400/1875], 0.21098813545703887\n",
            "Epoch [5/ 50], Step [1500/1875], 0.2125336834192276\n",
            "Epoch [5/ 50], Step [1600/1875], 0.21196998012065887\n",
            "Epoch [5/ 50], Step [1700/1875], 0.2096287258863449\n",
            "Epoch [5/ 50], Step [1800/1875], 0.20971758878231048\n",
            "Epoch [6/ 50], Step [100/1875], 0.21099646210670472\n",
            "Epoch [6/ 50], Step [200/1875], 0.20927699100971223\n",
            "Epoch [6/ 50], Step [300/1875], 0.20723316514492035\n",
            "Epoch [6/ 50], Step [400/1875], 0.20783051109313966\n",
            "Epoch [6/ 50], Step [500/1875], 0.20732741582393646\n",
            "Epoch [6/ 50], Step [600/1875], 0.20880250263214112\n",
            "Epoch [6/ 50], Step [700/1875], 0.2063914566040039\n",
            "Epoch [6/ 50], Step [800/1875], 0.20585364484786986\n",
            "Epoch [6/ 50], Step [900/1875], 0.205885449051857\n",
            "Epoch [6/ 50], Step [1000/1875], 0.2045390352010727\n",
            "Epoch [6/ 50], Step [1100/1875], 0.20517697739601135\n",
            "Epoch [6/ 50], Step [1200/1875], 0.20495147478580475\n",
            "Epoch [6/ 50], Step [1300/1875], 0.20412610256671906\n",
            "Epoch [6/ 50], Step [1400/1875], 0.20376377999782563\n",
            "Epoch [6/ 50], Step [1500/1875], 0.20149487435817717\n",
            "Epoch [6/ 50], Step [1600/1875], 0.20124738800525666\n",
            "Epoch [6/ 50], Step [1700/1875], 0.2017739098072052\n",
            "Epoch [6/ 50], Step [1800/1875], 0.20193593299388884\n",
            "Epoch [7/ 50], Step [100/1875], 0.20149466776847838\n",
            "Epoch [7/ 50], Step [200/1875], 0.2014608186483383\n",
            "Epoch [7/ 50], Step [300/1875], 0.1991982796192169\n",
            "Epoch [7/ 50], Step [400/1875], 0.1998635939359665\n",
            "Epoch [7/ 50], Step [500/1875], 0.19952024495601653\n",
            "Epoch [7/ 50], Step [600/1875], 0.19861789631843568\n",
            "Epoch [7/ 50], Step [700/1875], 0.1981681524515152\n",
            "Epoch [7/ 50], Step [800/1875], 0.1971448698043823\n",
            "Epoch [7/ 50], Step [900/1875], 0.1980745621919632\n",
            "Epoch [7/ 50], Step [1000/1875], 0.19687952780723572\n",
            "Epoch [7/ 50], Step [1100/1875], 0.1976965091228485\n",
            "Epoch [7/ 50], Step [1200/1875], 0.19564983332157135\n",
            "Epoch [7/ 50], Step [1300/1875], 0.19536073780059815\n",
            "Epoch [7/ 50], Step [1400/1875], 0.19605867660045623\n",
            "Epoch [7/ 50], Step [1500/1875], 0.196261465549469\n",
            "Epoch [7/ 50], Step [1600/1875], 0.19408454751968385\n",
            "Epoch [7/ 50], Step [1700/1875], 0.19418634235858917\n",
            "Epoch [7/ 50], Step [1800/1875], 0.1920781775712967\n",
            "Epoch [8/ 50], Step [100/1875], 0.193604279756546\n",
            "Epoch [8/ 50], Step [200/1875], 0.1942167329788208\n",
            "Epoch [8/ 50], Step [300/1875], 0.1922838487625122\n",
            "Epoch [8/ 50], Step [400/1875], 0.1938367840051651\n",
            "Epoch [8/ 50], Step [500/1875], 0.1920405856370926\n",
            "Epoch [8/ 50], Step [600/1875], 0.19203989720344544\n",
            "Epoch [8/ 50], Step [700/1875], 0.1910884976387024\n",
            "Epoch [8/ 50], Step [800/1875], 0.19145693707466124\n",
            "Epoch [8/ 50], Step [900/1875], 0.19086538457870483\n",
            "Epoch [8/ 50], Step [1000/1875], 0.19033646643161772\n",
            "Epoch [8/ 50], Step [1100/1875], 0.19156321692466735\n",
            "Epoch [8/ 50], Step [1200/1875], 0.19004616224765777\n",
            "Epoch [8/ 50], Step [1300/1875], 0.1885911192893982\n",
            "Epoch [8/ 50], Step [1400/1875], 0.1895419018268585\n",
            "Epoch [8/ 50], Step [1500/1875], 0.18945972669124603\n",
            "Epoch [8/ 50], Step [1600/1875], 0.18812075817584992\n",
            "Epoch [8/ 50], Step [1700/1875], 0.18810467219352722\n",
            "Epoch [8/ 50], Step [1800/1875], 0.18622533106803893\n",
            "Epoch [9/ 50], Step [100/1875], 0.186098849773407\n",
            "Epoch [9/ 50], Step [200/1875], 0.1870788584947586\n",
            "Epoch [9/ 50], Step [300/1875], 0.18588531184196472\n",
            "Epoch [9/ 50], Step [400/1875], 0.1861884365081787\n",
            "Epoch [9/ 50], Step [500/1875], 0.18633910596370698\n",
            "Epoch [9/ 50], Step [600/1875], 0.18691689372062684\n",
            "Epoch [9/ 50], Step [700/1875], 0.18428824257850646\n",
            "Epoch [9/ 50], Step [800/1875], 0.1839932358264923\n",
            "Epoch [9/ 50], Step [900/1875], 0.18446481037139892\n",
            "Epoch [9/ 50], Step [1000/1875], 0.18528339207172395\n",
            "Epoch [9/ 50], Step [1100/1875], 0.18429903304576875\n",
            "Epoch [9/ 50], Step [1200/1875], 0.1840971895456314\n",
            "Epoch [9/ 50], Step [1300/1875], 0.18351712429523467\n",
            "Epoch [9/ 50], Step [1400/1875], 0.1844113951921463\n",
            "Epoch [9/ 50], Step [1500/1875], 0.18364026653766632\n",
            "Epoch [9/ 50], Step [1600/1875], 0.18261730337142945\n",
            "Epoch [9/ 50], Step [1700/1875], 0.1826316055059433\n",
            "Epoch [9/ 50], Step [1800/1875], 0.18083109843730927\n",
            "Epoch [10/ 50], Step [100/1875], 0.18139791309833528\n",
            "Epoch [10/ 50], Step [200/1875], 0.18521094477176667\n",
            "Epoch [10/ 50], Step [300/1875], 0.17869562673568726\n",
            "Epoch [10/ 50], Step [400/1875], 0.1814575356245041\n",
            "Epoch [10/ 50], Step [500/1875], 0.1816352641582489\n",
            "Epoch [10/ 50], Step [600/1875], 0.18155399000644684\n",
            "Epoch [10/ 50], Step [700/1875], 0.17983398580551146\n",
            "Epoch [10/ 50], Step [800/1875], 0.18012612009048462\n",
            "Epoch [10/ 50], Step [900/1875], 0.17865431332588197\n",
            "Epoch [10/ 50], Step [1000/1875], 0.18115616273880006\n",
            "Epoch [10/ 50], Step [1100/1875], 0.17897082090377808\n",
            "Epoch [10/ 50], Step [1200/1875], 0.17888384747505187\n",
            "Epoch [10/ 50], Step [1300/1875], 0.17790767645835875\n",
            "Epoch [10/ 50], Step [1400/1875], 0.1766585451364517\n",
            "Epoch [10/ 50], Step [1500/1875], 0.17957035410404204\n",
            "Epoch [10/ 50], Step [1600/1875], 0.17752907955646516\n",
            "Epoch [10/ 50], Step [1700/1875], 0.17851232051849364\n",
            "Epoch [10/ 50], Step [1800/1875], 0.17633509361743926\n",
            "Epoch [11/ 50], Step [100/1875], 0.1756049209833145\n",
            "Epoch [11/ 50], Step [200/1875], 0.17773116874694825\n",
            "Epoch [11/ 50], Step [300/1875], 0.1743973034620285\n",
            "Epoch [11/ 50], Step [400/1875], 0.17769374477863312\n",
            "Epoch [11/ 50], Step [500/1875], 0.17558116042613983\n",
            "Epoch [11/ 50], Step [600/1875], 0.1769785943031311\n",
            "Epoch [11/ 50], Step [700/1875], 0.17485959208011628\n",
            "Epoch [11/ 50], Step [800/1875], 0.17568166363239288\n",
            "Epoch [11/ 50], Step [900/1875], 0.1736613278388977\n",
            "Epoch [11/ 50], Step [1000/1875], 0.1738244765996933\n",
            "Epoch [11/ 50], Step [1100/1875], 0.1742364903688431\n",
            "Epoch [11/ 50], Step [1200/1875], 0.17338981640338896\n",
            "Epoch [11/ 50], Step [1300/1875], 0.1726504348516464\n",
            "Epoch [11/ 50], Step [1400/1875], 0.17404091370105743\n",
            "Epoch [11/ 50], Step [1500/1875], 0.1749073361158371\n",
            "Epoch [11/ 50], Step [1600/1875], 0.17224977266788483\n",
            "Epoch [11/ 50], Step [1700/1875], 0.17122108149528503\n",
            "Epoch [11/ 50], Step [1800/1875], 0.17279661464691162\n",
            "Epoch [12/ 50], Step [100/1875], 0.17003419482707977\n",
            "Epoch [12/ 50], Step [200/1875], 0.17118500077724458\n",
            "Epoch [12/ 50], Step [300/1875], 0.16924169635772704\n",
            "Epoch [12/ 50], Step [400/1875], 0.17087759399414063\n",
            "Epoch [12/ 50], Step [500/1875], 0.17196376979351044\n",
            "Epoch [12/ 50], Step [600/1875], 0.17231836819648744\n",
            "Epoch [12/ 50], Step [700/1875], 0.1702876206636429\n",
            "Epoch [12/ 50], Step [800/1875], 0.1694420886039734\n",
            "Epoch [12/ 50], Step [900/1875], 0.1681995394229889\n",
            "Epoch [12/ 50], Step [1000/1875], 0.16931493151187896\n",
            "Epoch [12/ 50], Step [1100/1875], 0.16962511348724366\n",
            "Epoch [12/ 50], Step [1200/1875], 0.1670442885160446\n",
            "Epoch [12/ 50], Step [1300/1875], 0.16747762095928193\n",
            "Epoch [12/ 50], Step [1400/1875], 0.16572269761562347\n",
            "Epoch [12/ 50], Step [1500/1875], 0.16924689519405364\n",
            "Epoch [12/ 50], Step [1600/1875], 0.16656028974056244\n",
            "Epoch [12/ 50], Step [1700/1875], 0.16607361114025115\n",
            "Epoch [12/ 50], Step [1800/1875], 0.16711754322052003\n",
            "Epoch [13/ 50], Step [100/1875], 0.16503186476230622\n",
            "Epoch [13/ 50], Step [200/1875], 0.16805691719055177\n",
            "Epoch [13/ 50], Step [300/1875], 0.16472807395458222\n",
            "Epoch [13/ 50], Step [400/1875], 0.1662010644674301\n",
            "Epoch [13/ 50], Step [500/1875], 0.1643767261505127\n",
            "Epoch [13/ 50], Step [600/1875], 0.16736464011669158\n",
            "Epoch [13/ 50], Step [700/1875], 0.16450510156154632\n",
            "Epoch [13/ 50], Step [800/1875], 0.16598118150234223\n",
            "Epoch [13/ 50], Step [900/1875], 0.16252668011188506\n",
            "Epoch [13/ 50], Step [1000/1875], 0.16188470768928528\n",
            "Epoch [13/ 50], Step [1100/1875], 0.16315230286121368\n",
            "Epoch [13/ 50], Step [1200/1875], 0.16042498826980592\n",
            "Epoch [13/ 50], Step [1300/1875], 0.16178340578079223\n",
            "Epoch [13/ 50], Step [1400/1875], 0.15999842059612274\n",
            "Epoch [13/ 50], Step [1500/1875], 0.16402453064918518\n",
            "Epoch [13/ 50], Step [1600/1875], 0.16062693428993224\n",
            "Epoch [13/ 50], Step [1700/1875], 0.16095603942871095\n",
            "Epoch [13/ 50], Step [1800/1875], 0.1632728250026703\n",
            "Epoch [14/ 50], Step [100/1875], 0.15880931985378266\n",
            "Epoch [14/ 50], Step [200/1875], 0.16247650265693664\n",
            "Epoch [14/ 50], Step [300/1875], 0.15915634417533875\n",
            "Epoch [14/ 50], Step [400/1875], 0.15920562636852265\n",
            "Epoch [14/ 50], Step [500/1875], 0.15915350532531738\n",
            "Epoch [14/ 50], Step [600/1875], 0.16177025651931762\n",
            "Epoch [14/ 50], Step [700/1875], 0.15773684191703796\n",
            "Epoch [14/ 50], Step [800/1875], 0.16149720549583435\n",
            "Epoch [14/ 50], Step [900/1875], 0.15784605717658998\n",
            "Epoch [14/ 50], Step [1000/1875], 0.1568853987455368\n",
            "Epoch [14/ 50], Step [1100/1875], 0.15660321831703186\n",
            "Epoch [14/ 50], Step [1200/1875], 0.15430214536190032\n",
            "Epoch [14/ 50], Step [1300/1875], 0.15498522996902467\n",
            "Epoch [14/ 50], Step [1400/1875], 0.15524463737010955\n",
            "Epoch [14/ 50], Step [1500/1875], 0.15671947121620178\n",
            "Epoch [14/ 50], Step [1600/1875], 0.15418696427345277\n",
            "Epoch [14/ 50], Step [1700/1875], 0.15405543100833893\n",
            "Epoch [14/ 50], Step [1800/1875], 0.15490558207035066\n",
            "Epoch [15/ 50], Step [100/1875], 0.15198883938789368\n",
            "Epoch [15/ 50], Step [200/1875], 0.15312658035755158\n",
            "Epoch [15/ 50], Step [300/1875], 0.15076396989822388\n",
            "Epoch [15/ 50], Step [400/1875], 0.14985309040546418\n",
            "Epoch [15/ 50], Step [500/1875], 0.15398408842086792\n",
            "Epoch [15/ 50], Step [600/1875], 0.1526212385892868\n",
            "Epoch [15/ 50], Step [700/1875], 0.14960234427452088\n",
            "Epoch [15/ 50], Step [800/1875], 0.1516162487268448\n",
            "Epoch [15/ 50], Step [900/1875], 0.14847167003154754\n",
            "Epoch [15/ 50], Step [1000/1875], 0.14580320501327515\n",
            "Epoch [15/ 50], Step [1100/1875], 0.14952660822868347\n",
            "Epoch [15/ 50], Step [1200/1875], 0.14519796466827392\n",
            "Epoch [15/ 50], Step [1300/1875], 0.14869553577899933\n",
            "Epoch [15/ 50], Step [1400/1875], 0.1447771497964859\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-7f86f41a1b15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0melem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0melem_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2h5Dzgct_vp",
        "outputId": "daa02ab1-3b09-4132-ea4f-34632f8ade67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "df = pd.DataFrame(columns=['# Id', 'Category'])\n",
        "#device = torch.device('cpu')\n",
        "with torch.no_grad():\n",
        "  i=0\n",
        "  for data in testing:\n",
        "    images,labels = data\n",
        "    images = data[0].to(device)[None, :]\n",
        "    images = images.permute(1,0,2, 3)\n",
        "    outputs = model(images)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    label_predicted = labels_encoder.inverse_transform(predicted.cpu().numpy())\n",
        "    prediction = str(label_predicted[0])\n",
        "    df.loc[i] = [i, prediction]\n",
        "    i += 1\n",
        "\n",
        "df = df.iloc[:15001]\n",
        "\n",
        "df"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th># Id</th>\n",
              "      <th>Category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>000001000000010000000000000000000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>000000000100000000000010000000000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>001000000000000000000100000000000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>000100000000000000000000000000000010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>001000000000000000000100000000000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14995</th>\n",
              "      <td>14995</td>\n",
              "      <td>000000000110000000000000000000000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14996</th>\n",
              "      <td>14996</td>\n",
              "      <td>000100000000000000000000000000000001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14997</th>\n",
              "      <td>14997</td>\n",
              "      <td>000000001000000000000001000000000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14998</th>\n",
              "      <td>14998</td>\n",
              "      <td>000100000000000000000000000000000001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14999</th>\n",
              "      <td>14999</td>\n",
              "      <td>010000000000000000000000000000010000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>15000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        # Id                              Category\n",
              "0          0  000001000000010000000000000000000000\n",
              "1          1  000000000100000000000010000000000000\n",
              "2          2  001000000000000000000100000000000000\n",
              "3          3  000100000000000000000000000000000010\n",
              "4          4  001000000000000000000100000000000000\n",
              "...      ...                                   ...\n",
              "14995  14995  000000000110000000000000000000000000\n",
              "14996  14996  000100000000000000000000000000000001\n",
              "14997  14997  000000001000000000000001000000000000\n",
              "14998  14998  000100000000000000000000000000000001\n",
              "14999  14999  010000000000000000000000000000010000\n",
              "\n",
              "[15000 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4opCeTVgvvGH"
      },
      "source": [
        "from datetime import datetime\n",
        "filename = 'kaggle_g19_{}.csv'.format(datetime.now())\n",
        "df.to_csv(filename, sep=',', float_format='{:36}', index=False)"
      ],
      "execution_count": 30,
      "outputs": []
    }
  ]
}
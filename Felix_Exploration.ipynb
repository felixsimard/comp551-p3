{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Felix-Exploration.ipynb",
      "provenance": [],
      "mount_file_id": "https://github.com/felixsimard/comp551-p3/blob/main/Felix_Exploration.ipynb",
      "authorship_tag": "ABX9TyP1ddYI5Qq48VE4Csn1875t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/felixsimard/comp551-p3/blob/main/Felix_Exploration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9d--OU0IF0S"
      },
      "source": [
        "# Felix's Notebook for exploring the assignment"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yNW2EISINDi"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "from PIL import Image\n",
        "from sklearn import preprocessing"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xgfx5EC0kW8V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e8b9533-712a-4a9d-a29c-23b63885f28c"
      },
      "source": [
        "# Reference: https://www.youtube.com/watch?v=pDdP0TFzsoQ\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3doYI1lAbe9"
      },
      "source": [
        "def imshow(img):\n",
        "    # img = img / 2 + 0.5     # unnormalize\n",
        "    # npimg = img.numpy()\n",
        "    plt.imshow(img)\n",
        "    # plt.imshow(np.transpose(npimg, (1, 2, 0))) \n",
        "    plt.show()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "batbKOaCj6fa"
      },
      "source": [
        "def load_data(filename, data_path='/content/drive/MyDrive/P3-COMP551-FALL2021/'):\n",
        "    from google.colab import drive\n",
        "    drive.mount(\"/content/drive\")\n",
        "    loaded_pkl = None\n",
        "    try:\n",
        "        pkl_buffered = open(data_path+''+filename,'rb')\n",
        "        loaded_pkl = pickle.load(pkl_buffered)\n",
        "    except Exception as e:\n",
        "        print(\"Error loading data: {}\".format(e))\n",
        "    return loaded_pkl\n",
        "    "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iuvaFp3CvYH-",
        "outputId": "306b69d0-e852-486e-ce06-33c612d23118"
      },
      "source": [
        "# Load data\n",
        "train_l = load_data(\"images_l.pkl\")\n",
        "train_ul = load_data(\"images_ul.pkl\")\n",
        "labels_l = load_data(\"labels_l.pkl\")\n",
        "test_ul = load_data(\"images_test.pkl\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ds4PQvPLM4OR"
      },
      "source": [
        ""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwO8NOgHkd23"
      },
      "source": [
        "# Reference: https://stackoverflow.com/questions/44429199/how-to-load-a-list-of-numpy-arrays-to-pytorch-dataset-loader\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, data, targets, transform=None):\n",
        "        self.data = data\n",
        "        self.targets = torch.LongTensor(targets)\n",
        "        self.transform = transform\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        x = self.data[index]\n",
        "        y = self.targets[index]\n",
        "        \n",
        "        if self.transform:\n",
        "            x = Image.fromarray(self.data[index].astype(np.uint8).transpose(1,2,0))\n",
        "            x = self.transform(x)\n",
        "        \n",
        "        return x, y\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDFiIo7cRWsN"
      },
      "source": [
        "# Hyper-parameters\n",
        "NUM_EPOCHS = 1\n",
        "BATCH_SIZE = 1\n",
        "LEARNING_RATE = 0.001\n",
        "MOMENTUM = 0.9\n",
        "WEIGHT_DECAY = 0.0001"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_X-KfukA00R"
      },
      "source": [
        "# Tensor, Transform, Datasets, Dataloaders\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "# Tensor\n",
        "train_l_tensor = torch.Tensor(train_l)\n",
        "\n",
        "\n",
        "def labelize(lst):\n",
        "    bin_str = \"\".join(str(int(i)) for i in lst)\n",
        "    return bin_str\n",
        "\n",
        "# Labels logic\n",
        "labels_l_lst = labels_l.tolist()\n",
        "labels_l_lst = [labelize(lst) for lst in labels_l_lst]\n",
        "labels_encoder = preprocessing.LabelEncoder()\n",
        "targets = labels_encoder.fit_transform(labels_l_lst)\n",
        "labels_l_tensor = torch.as_tensor(targets)\n",
        "\n",
        "# labels_l_tensor = torch.argmax(torch.Tensor(labels_l), dim=1) # THIS IS KEY FOR THE LABELS\n",
        "\n",
        "# Datasets\n",
        "train_l_dataset = TensorDataset(train_l_tensor, labels_l_tensor)\n",
        "train_l_dataloader = DataLoader(train_l_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# Test\n",
        "test_ul_tensor = torch.Tensor(test_ul)\n",
        "test_labels = torch.Tensor(np.zeros(len(test_ul)))\n",
        "test_ul_dataset = TensorDataset(test_ul_tensor, test_labels)\n",
        "test_ul_dataloader = DataLoader(test_ul_dataset, batch_size=BATCH_SIZE, shuffle=False)\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXuPBNFHvY6U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85590c5b-aceb-4ec3-a4b0-834aaed18817"
      },
      "source": [
        "# Define labels\n",
        "# Consider upper case and lower case letters?\n",
        "labels = []\n",
        "for l in range(26):\n",
        "    letter_str = [0.0 for i in range(26)]\n",
        "    letter_str[l] = 1.0\n",
        "    for d in range(10):\n",
        "        digits_str = [0.0 for j in range(10)]\n",
        "        digits_str[d] = 1.0\n",
        "        c = digits_str + letter_str\n",
        "        # c = \"\".join(c_str)\n",
        "        labels.append(c)\n",
        "print(labels[:5])\n",
        "print(len(labels))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]\n",
            "260\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooBvvB2DE4Vc"
      },
      "source": [
        "# Implement CONV Net\n",
        "\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self, in_channels=1, num_classes=260):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.num_classes = num_classes\n",
        "        # self.model = torchvision.models.resnet34(pretrained=False)\n",
        "        self.conv1 = nn.Conv2d(in_channels, 6, 5) # input channel (rgb), output channel, kernel size \n",
        "        self.pool = nn.MaxPool2d(2, 2) # define 2x2 stride for max-pooling\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5) # input channel size = output channel size of previous conv layer\n",
        "        self.fc1 = nn.Linear(16*11*11, 120) # fully connected layer\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, num_classes)   \n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x))) # activation function does not change size\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16*11*11) # -1 tells PyTorch to infer num batches # flatten tensor\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x) # no activation at end, softmax included in CrossEntropyLoss\n",
        "        return x\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yc2s6YwqN28x",
        "outputId": "127f9e1b-c95f-4a0e-d191-e949d32c0428"
      },
      "source": [
        "# Test model flow\n",
        "model_test = ConvNet()\n",
        "x = torch.randn(BATCH_SIZE, 1, 56, 56)\n",
        "print(model_test(x).shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 260])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6Lrt1pstW72"
      },
      "source": [
        ""
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Go-n5-iKHQxc",
        "outputId": "2d4cf12b-0c3a-4c86-caf2-73461e7750e0"
      },
      "source": [
        "model = ConvNet().to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss() # includes softmax\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
        "\n",
        "n_total_steps = len(train_l_dataloader)\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_l_dataloader, 0):\n",
        "        # get inputs, data is a list of [inputs, labels]\n",
        "        inputs = data[0].to(device)[None, :]\n",
        "        inputs = inputs.permute(1, 0, 2, 3)\n",
        "        labels = data[1].to(device)\n",
        "\n",
        "        # print(\"Inputs:\", inputs.shape)\n",
        "        # print(\"labels:\", labels)\n",
        "        # print(\"labels:\", labels.shape)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if (i+1) % 100 == 0: # print every 1000 mini-batches\n",
        "            print(f'Epoch [{epoch+1}/{NUM_EPOCHS}], Step [{i+1}/{len(train_l_dataloader)}], Loss: {loss.item():.4f}')\n",
        "            running_loss = 0.0\n",
        "        \n",
        "\n",
        "print('Finished Training')\n",
        "PATH = './cnn.pth'\n",
        "torch.save(model.state_dict(), PATH)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/1], Step [100/30000], Loss: 5.4745\n",
            "Epoch [1/1], Step [200/30000], Loss: 5.6175\n",
            "Epoch [1/1], Step [300/30000], Loss: 5.7527\n",
            "Epoch [1/1], Step [400/30000], Loss: 5.5045\n",
            "Epoch [1/1], Step [500/30000], Loss: 5.7164\n",
            "Epoch [1/1], Step [600/30000], Loss: 5.5259\n",
            "Epoch [1/1], Step [700/30000], Loss: 5.2797\n",
            "Epoch [1/1], Step [800/30000], Loss: 5.4604\n",
            "Epoch [1/1], Step [900/30000], Loss: 5.5776\n",
            "Epoch [1/1], Step [1000/30000], Loss: 5.4965\n",
            "Epoch [1/1], Step [1100/30000], Loss: 5.5092\n",
            "Epoch [1/1], Step [1200/30000], Loss: 5.5223\n",
            "Epoch [1/1], Step [1300/30000], Loss: 5.6723\n",
            "Epoch [1/1], Step [1400/30000], Loss: 5.5747\n",
            "Epoch [1/1], Step [1500/30000], Loss: 5.4668\n",
            "Epoch [1/1], Step [1600/30000], Loss: 5.7434\n",
            "Epoch [1/1], Step [1700/30000], Loss: 5.5355\n",
            "Epoch [1/1], Step [1800/30000], Loss: 5.5904\n",
            "Epoch [1/1], Step [1900/30000], Loss: 5.6093\n",
            "Epoch [1/1], Step [2000/30000], Loss: 5.4297\n",
            "Epoch [1/1], Step [2100/30000], Loss: 5.3864\n",
            "Epoch [1/1], Step [2200/30000], Loss: 5.5115\n",
            "Epoch [1/1], Step [2300/30000], Loss: 5.0263\n",
            "Epoch [1/1], Step [2400/30000], Loss: 4.6902\n",
            "Epoch [1/1], Step [2500/30000], Loss: 5.4480\n",
            "Epoch [1/1], Step [2600/30000], Loss: 5.6004\n",
            "Epoch [1/1], Step [2700/30000], Loss: 5.5243\n",
            "Epoch [1/1], Step [2800/30000], Loss: 5.4278\n",
            "Epoch [1/1], Step [2900/30000], Loss: 5.5552\n",
            "Epoch [1/1], Step [3000/30000], Loss: 5.6382\n",
            "Epoch [1/1], Step [3100/30000], Loss: 5.5844\n",
            "Epoch [1/1], Step [3200/30000], Loss: 5.4400\n",
            "Epoch [1/1], Step [3300/30000], Loss: 5.6342\n",
            "Epoch [1/1], Step [3400/30000], Loss: 5.6664\n",
            "Epoch [1/1], Step [3500/30000], Loss: 5.4631\n",
            "Epoch [1/1], Step [3600/30000], Loss: 5.4806\n",
            "Epoch [1/1], Step [3700/30000], Loss: 5.4515\n",
            "Epoch [1/1], Step [3800/30000], Loss: 5.6531\n",
            "Epoch [1/1], Step [3900/30000], Loss: 5.4828\n",
            "Epoch [1/1], Step [4000/30000], Loss: 5.5157\n",
            "Epoch [1/1], Step [4100/30000], Loss: 5.5198\n",
            "Epoch [1/1], Step [4200/30000], Loss: 5.5920\n",
            "Epoch [1/1], Step [4300/30000], Loss: 4.4117\n",
            "Epoch [1/1], Step [4400/30000], Loss: 5.3937\n",
            "Epoch [1/1], Step [4500/30000], Loss: 4.9024\n",
            "Epoch [1/1], Step [4600/30000], Loss: 5.5725\n",
            "Epoch [1/1], Step [4700/30000], Loss: 5.6821\n",
            "Epoch [1/1], Step [4800/30000], Loss: 5.5857\n",
            "Epoch [1/1], Step [4900/30000], Loss: 5.4362\n",
            "Epoch [1/1], Step [5000/30000], Loss: 5.4831\n",
            "Epoch [1/1], Step [5100/30000], Loss: 5.5753\n",
            "Epoch [1/1], Step [5200/30000], Loss: 5.5954\n",
            "Epoch [1/1], Step [5300/30000], Loss: 5.3966\n",
            "Epoch [1/1], Step [5400/30000], Loss: 5.5760\n",
            "Epoch [1/1], Step [5500/30000], Loss: 5.6045\n",
            "Epoch [1/1], Step [5600/30000], Loss: 4.7335\n",
            "Epoch [1/1], Step [5700/30000], Loss: 5.4982\n",
            "Epoch [1/1], Step [5800/30000], Loss: 4.1011\n",
            "Epoch [1/1], Step [5900/30000], Loss: 5.6901\n",
            "Epoch [1/1], Step [6000/30000], Loss: 5.5753\n",
            "Epoch [1/1], Step [6100/30000], Loss: 4.6263\n",
            "Epoch [1/1], Step [6200/30000], Loss: 5.4662\n",
            "Epoch [1/1], Step [6300/30000], Loss: 4.3615\n",
            "Epoch [1/1], Step [6400/30000], Loss: 5.7109\n",
            "Epoch [1/1], Step [6500/30000], Loss: 5.5041\n",
            "Epoch [1/1], Step [6600/30000], Loss: 5.4642\n",
            "Epoch [1/1], Step [6700/30000], Loss: 5.6128\n",
            "Epoch [1/1], Step [6800/30000], Loss: 3.6983\n",
            "Epoch [1/1], Step [6900/30000], Loss: 5.5988\n",
            "Epoch [1/1], Step [7000/30000], Loss: 5.6323\n",
            "Epoch [1/1], Step [7100/30000], Loss: 5.5253\n",
            "Epoch [1/1], Step [7200/30000], Loss: 5.5172\n",
            "Epoch [1/1], Step [7300/30000], Loss: 5.5440\n",
            "Epoch [1/1], Step [7400/30000], Loss: 4.4810\n",
            "Epoch [1/1], Step [7500/30000], Loss: 5.3926\n",
            "Epoch [1/1], Step [7600/30000], Loss: 4.4145\n",
            "Epoch [1/1], Step [7700/30000], Loss: 5.6393\n",
            "Epoch [1/1], Step [7800/30000], Loss: 5.5976\n",
            "Epoch [1/1], Step [7900/30000], Loss: 5.4971\n",
            "Epoch [1/1], Step [8000/30000], Loss: 5.4694\n",
            "Epoch [1/1], Step [8100/30000], Loss: 5.2718\n",
            "Epoch [1/1], Step [8200/30000], Loss: 5.4400\n",
            "Epoch [1/1], Step [8300/30000], Loss: 5.5717\n",
            "Epoch [1/1], Step [8400/30000], Loss: 4.0940\n",
            "Epoch [1/1], Step [8500/30000], Loss: 3.7509\n",
            "Epoch [1/1], Step [8600/30000], Loss: 5.4603\n",
            "Epoch [1/1], Step [8700/30000], Loss: 5.5802\n",
            "Epoch [1/1], Step [8800/30000], Loss: 5.5262\n",
            "Epoch [1/1], Step [8900/30000], Loss: 5.5005\n",
            "Epoch [1/1], Step [9000/30000], Loss: 5.5514\n",
            "Epoch [1/1], Step [9100/30000], Loss: 5.4839\n",
            "Epoch [1/1], Step [9200/30000], Loss: 5.4052\n",
            "Epoch [1/1], Step [9300/30000], Loss: 5.5701\n",
            "Epoch [1/1], Step [9400/30000], Loss: 5.6185\n",
            "Epoch [1/1], Step [9500/30000], Loss: 5.2717\n",
            "Epoch [1/1], Step [9600/30000], Loss: 5.0069\n",
            "Epoch [1/1], Step [9700/30000], Loss: 5.6424\n",
            "Epoch [1/1], Step [9800/30000], Loss: 5.4042\n",
            "Epoch [1/1], Step [9900/30000], Loss: 5.3217\n",
            "Epoch [1/1], Step [10000/30000], Loss: 5.6097\n",
            "Epoch [1/1], Step [10100/30000], Loss: 5.6697\n",
            "Epoch [1/1], Step [10200/30000], Loss: 5.3381\n",
            "Epoch [1/1], Step [10300/30000], Loss: 5.6801\n",
            "Epoch [1/1], Step [10400/30000], Loss: 5.6777\n",
            "Epoch [1/1], Step [10500/30000], Loss: 5.3438\n",
            "Epoch [1/1], Step [10600/30000], Loss: 4.0211\n",
            "Epoch [1/1], Step [10700/30000], Loss: 5.4792\n",
            "Epoch [1/1], Step [10800/30000], Loss: 5.6445\n",
            "Epoch [1/1], Step [10900/30000], Loss: 4.3947\n",
            "Epoch [1/1], Step [11000/30000], Loss: 5.4095\n",
            "Epoch [1/1], Step [11100/30000], Loss: 5.3526\n",
            "Epoch [1/1], Step [11200/30000], Loss: 5.5250\n",
            "Epoch [1/1], Step [11300/30000], Loss: 5.5559\n",
            "Epoch [1/1], Step [11400/30000], Loss: 5.2328\n",
            "Epoch [1/1], Step [11500/30000], Loss: 5.4921\n",
            "Epoch [1/1], Step [11600/30000], Loss: 5.5504\n",
            "Epoch [1/1], Step [11700/30000], Loss: 5.4812\n",
            "Epoch [1/1], Step [11800/30000], Loss: 5.7392\n",
            "Epoch [1/1], Step [11900/30000], Loss: 5.3606\n",
            "Epoch [1/1], Step [12000/30000], Loss: 4.3938\n",
            "Epoch [1/1], Step [12100/30000], Loss: 5.8123\n",
            "Epoch [1/1], Step [12200/30000], Loss: 5.6690\n",
            "Epoch [1/1], Step [12300/30000], Loss: 5.1408\n",
            "Epoch [1/1], Step [12400/30000], Loss: 4.2093\n",
            "Epoch [1/1], Step [12500/30000], Loss: 5.5502\n",
            "Epoch [1/1], Step [12600/30000], Loss: 5.4861\n",
            "Epoch [1/1], Step [12700/30000], Loss: 5.6653\n",
            "Epoch [1/1], Step [12800/30000], Loss: 4.4364\n",
            "Epoch [1/1], Step [12900/30000], Loss: 5.3145\n",
            "Epoch [1/1], Step [13000/30000], Loss: 5.4321\n",
            "Epoch [1/1], Step [13100/30000], Loss: 3.9836\n",
            "Epoch [1/1], Step [13200/30000], Loss: 5.5012\n",
            "Epoch [1/1], Step [13300/30000], Loss: 5.4816\n",
            "Epoch [1/1], Step [13400/30000], Loss: 4.2072\n",
            "Epoch [1/1], Step [13500/30000], Loss: 5.2372\n",
            "Epoch [1/1], Step [13600/30000], Loss: 4.6653\n",
            "Epoch [1/1], Step [13700/30000], Loss: 5.4060\n",
            "Epoch [1/1], Step [13800/30000], Loss: 5.3213\n",
            "Epoch [1/1], Step [13900/30000], Loss: 5.2191\n",
            "Epoch [1/1], Step [14000/30000], Loss: 5.6656\n",
            "Epoch [1/1], Step [14100/30000], Loss: 5.3740\n",
            "Epoch [1/1], Step [14200/30000], Loss: 5.7229\n",
            "Epoch [1/1], Step [14300/30000], Loss: 5.1106\n",
            "Epoch [1/1], Step [14400/30000], Loss: 5.4617\n",
            "Epoch [1/1], Step [14500/30000], Loss: 5.7450\n",
            "Epoch [1/1], Step [14600/30000], Loss: 5.1020\n",
            "Epoch [1/1], Step [14700/30000], Loss: 4.8666\n",
            "Epoch [1/1], Step [14800/30000], Loss: 5.0301\n",
            "Epoch [1/1], Step [14900/30000], Loss: 5.3146\n",
            "Epoch [1/1], Step [15000/30000], Loss: 5.8352\n",
            "Epoch [1/1], Step [15100/30000], Loss: 5.5444\n",
            "Epoch [1/1], Step [15200/30000], Loss: 5.2202\n",
            "Epoch [1/1], Step [15300/30000], Loss: 4.1733\n",
            "Epoch [1/1], Step [15400/30000], Loss: 5.2916\n",
            "Epoch [1/1], Step [15500/30000], Loss: 6.0557\n",
            "Epoch [1/1], Step [15600/30000], Loss: 5.1134\n",
            "Epoch [1/1], Step [15700/30000], Loss: 5.5008\n",
            "Epoch [1/1], Step [15800/30000], Loss: 5.5074\n",
            "Epoch [1/1], Step [15900/30000], Loss: 5.2323\n",
            "Epoch [1/1], Step [16000/30000], Loss: 5.1332\n",
            "Epoch [1/1], Step [16100/30000], Loss: 3.4623\n",
            "Epoch [1/1], Step [16200/30000], Loss: 5.5395\n",
            "Epoch [1/1], Step [16300/30000], Loss: 5.5028\n",
            "Epoch [1/1], Step [16400/30000], Loss: 5.0609\n",
            "Epoch [1/1], Step [16500/30000], Loss: 5.1955\n",
            "Epoch [1/1], Step [16600/30000], Loss: 4.1431\n",
            "Epoch [1/1], Step [16700/30000], Loss: 6.0238\n",
            "Epoch [1/1], Step [16800/30000], Loss: 5.4159\n",
            "Epoch [1/1], Step [16900/30000], Loss: 5.1130\n",
            "Epoch [1/1], Step [17000/30000], Loss: 6.0139\n",
            "Epoch [1/1], Step [17100/30000], Loss: 5.0747\n",
            "Epoch [1/1], Step [17200/30000], Loss: 5.4883\n",
            "Epoch [1/1], Step [17300/30000], Loss: 5.2533\n",
            "Epoch [1/1], Step [17400/30000], Loss: 4.2076\n",
            "Epoch [1/1], Step [17500/30000], Loss: 4.0774\n",
            "Epoch [1/1], Step [17600/30000], Loss: 5.2069\n",
            "Epoch [1/1], Step [17700/30000], Loss: 5.2638\n",
            "Epoch [1/1], Step [17800/30000], Loss: 5.1574\n",
            "Epoch [1/1], Step [17900/30000], Loss: 5.2075\n",
            "Epoch [1/1], Step [18000/30000], Loss: 5.4604\n",
            "Epoch [1/1], Step [18100/30000], Loss: 5.3927\n",
            "Epoch [1/1], Step [18200/30000], Loss: 5.6382\n",
            "Epoch [1/1], Step [18300/30000], Loss: 5.5831\n",
            "Epoch [1/1], Step [18400/30000], Loss: 5.4651\n",
            "Epoch [1/1], Step [18500/30000], Loss: 5.1732\n",
            "Epoch [1/1], Step [18600/30000], Loss: 5.0571\n",
            "Epoch [1/1], Step [18700/30000], Loss: 5.4779\n",
            "Epoch [1/1], Step [18800/30000], Loss: 5.3145\n",
            "Epoch [1/1], Step [18900/30000], Loss: 5.6208\n",
            "Epoch [1/1], Step [19000/30000], Loss: 5.4101\n",
            "Epoch [1/1], Step [19100/30000], Loss: 5.3868\n",
            "Epoch [1/1], Step [19200/30000], Loss: 4.7060\n",
            "Epoch [1/1], Step [19300/30000], Loss: 5.4435\n",
            "Epoch [1/1], Step [19400/30000], Loss: 4.8883\n",
            "Epoch [1/1], Step [19500/30000], Loss: 5.2312\n",
            "Epoch [1/1], Step [19600/30000], Loss: 3.8064\n",
            "Epoch [1/1], Step [19700/30000], Loss: 5.4067\n",
            "Epoch [1/1], Step [19800/30000], Loss: 5.2726\n",
            "Epoch [1/1], Step [19900/30000], Loss: 4.0370\n",
            "Epoch [1/1], Step [20000/30000], Loss: 5.4389\n",
            "Epoch [1/1], Step [20100/30000], Loss: 5.1822\n",
            "Epoch [1/1], Step [20200/30000], Loss: 5.0626\n",
            "Epoch [1/1], Step [20300/30000], Loss: 5.2719\n",
            "Epoch [1/1], Step [20400/30000], Loss: 5.3508\n",
            "Epoch [1/1], Step [20500/30000], Loss: 5.4194\n",
            "Epoch [1/1], Step [20600/30000], Loss: 5.5649\n",
            "Epoch [1/1], Step [20700/30000], Loss: 5.5724\n",
            "Epoch [1/1], Step [20800/30000], Loss: 5.5164\n",
            "Epoch [1/1], Step [20900/30000], Loss: 4.2823\n",
            "Epoch [1/1], Step [21000/30000], Loss: 5.3594\n",
            "Epoch [1/1], Step [21100/30000], Loss: 5.2391\n",
            "Epoch [1/1], Step [21200/30000], Loss: 5.8041\n",
            "Epoch [1/1], Step [21300/30000], Loss: 6.0565\n",
            "Epoch [1/1], Step [21400/30000], Loss: 5.1974\n",
            "Epoch [1/1], Step [21500/30000], Loss: 5.3041\n",
            "Epoch [1/1], Step [21600/30000], Loss: 5.7495\n",
            "Epoch [1/1], Step [21700/30000], Loss: 5.4793\n",
            "Epoch [1/1], Step [21800/30000], Loss: 5.2421\n",
            "Epoch [1/1], Step [21900/30000], Loss: 5.3144\n",
            "Epoch [1/1], Step [22000/30000], Loss: 5.3580\n",
            "Epoch [1/1], Step [22100/30000], Loss: 5.5415\n",
            "Epoch [1/1], Step [22200/30000], Loss: 4.9522\n",
            "Epoch [1/1], Step [22300/30000], Loss: 4.6913\n",
            "Epoch [1/1], Step [22400/30000], Loss: 5.3878\n",
            "Epoch [1/1], Step [22500/30000], Loss: 5.5360\n",
            "Epoch [1/1], Step [22600/30000], Loss: 5.4256\n",
            "Epoch [1/1], Step [22700/30000], Loss: 5.3963\n",
            "Epoch [1/1], Step [22800/30000], Loss: 4.4195\n",
            "Epoch [1/1], Step [22900/30000], Loss: 4.1100\n",
            "Epoch [1/1], Step [23000/30000], Loss: 5.3851\n",
            "Epoch [1/1], Step [23100/30000], Loss: 4.3058\n",
            "Epoch [1/1], Step [23200/30000], Loss: 4.3710\n",
            "Epoch [1/1], Step [23300/30000], Loss: 5.3648\n",
            "Epoch [1/1], Step [23400/30000], Loss: 5.4203\n",
            "Epoch [1/1], Step [23500/30000], Loss: 4.5557\n",
            "Epoch [1/1], Step [23600/30000], Loss: 5.5900\n",
            "Epoch [1/1], Step [23700/30000], Loss: 4.5803\n",
            "Epoch [1/1], Step [23800/30000], Loss: 5.4166\n",
            "Epoch [1/1], Step [23900/30000], Loss: 5.2400\n",
            "Epoch [1/1], Step [24000/30000], Loss: 4.2916\n",
            "Epoch [1/1], Step [24100/30000], Loss: 4.1223\n",
            "Epoch [1/1], Step [24200/30000], Loss: 5.3341\n",
            "Epoch [1/1], Step [24300/30000], Loss: 4.0282\n",
            "Epoch [1/1], Step [24400/30000], Loss: 5.6377\n",
            "Epoch [1/1], Step [24500/30000], Loss: 4.0754\n",
            "Epoch [1/1], Step [24600/30000], Loss: 5.1990\n",
            "Epoch [1/1], Step [24700/30000], Loss: 4.6866\n",
            "Epoch [1/1], Step [24800/30000], Loss: 4.3014\n",
            "Epoch [1/1], Step [24900/30000], Loss: 5.7543\n",
            "Epoch [1/1], Step [25000/30000], Loss: 5.1708\n",
            "Epoch [1/1], Step [25100/30000], Loss: 4.2058\n",
            "Epoch [1/1], Step [25200/30000], Loss: 4.8522\n",
            "Epoch [1/1], Step [25300/30000], Loss: 5.6157\n",
            "Epoch [1/1], Step [25400/30000], Loss: 5.4677\n",
            "Epoch [1/1], Step [25500/30000], Loss: 5.2232\n",
            "Epoch [1/1], Step [25600/30000], Loss: 5.4312\n",
            "Epoch [1/1], Step [25700/30000], Loss: 5.7028\n",
            "Epoch [1/1], Step [25800/30000], Loss: 4.0967\n",
            "Epoch [1/1], Step [25900/30000], Loss: 5.3237\n",
            "Epoch [1/1], Step [26000/30000], Loss: 3.6098\n",
            "Epoch [1/1], Step [26100/30000], Loss: 5.4595\n",
            "Epoch [1/1], Step [26200/30000], Loss: 5.5668\n",
            "Epoch [1/1], Step [26300/30000], Loss: 5.7590\n",
            "Epoch [1/1], Step [26400/30000], Loss: 4.9366\n",
            "Epoch [1/1], Step [26500/30000], Loss: 5.4151\n",
            "Epoch [1/1], Step [26600/30000], Loss: 5.2370\n",
            "Epoch [1/1], Step [26700/30000], Loss: 4.8416\n",
            "Epoch [1/1], Step [26800/30000], Loss: 4.0277\n",
            "Epoch [1/1], Step [26900/30000], Loss: 5.1677\n",
            "Epoch [1/1], Step [27000/30000], Loss: 5.0299\n",
            "Epoch [1/1], Step [27100/30000], Loss: 5.2230\n",
            "Epoch [1/1], Step [27200/30000], Loss: 5.5332\n",
            "Epoch [1/1], Step [27300/30000], Loss: 5.4886\n",
            "Epoch [1/1], Step [27400/30000], Loss: 4.6883\n",
            "Epoch [1/1], Step [27500/30000], Loss: 4.1058\n",
            "Epoch [1/1], Step [27600/30000], Loss: 5.4540\n",
            "Epoch [1/1], Step [27700/30000], Loss: 5.3539\n",
            "Epoch [1/1], Step [27800/30000], Loss: 4.6908\n",
            "Epoch [1/1], Step [27900/30000], Loss: 5.5665\n",
            "Epoch [1/1], Step [28000/30000], Loss: 5.2454\n",
            "Epoch [1/1], Step [28100/30000], Loss: 4.1392\n",
            "Epoch [1/1], Step [28200/30000], Loss: 5.2941\n",
            "Epoch [1/1], Step [28300/30000], Loss: 5.1789\n",
            "Epoch [1/1], Step [28400/30000], Loss: 5.5487\n",
            "Epoch [1/1], Step [28500/30000], Loss: 4.7159\n",
            "Epoch [1/1], Step [28600/30000], Loss: 5.4745\n",
            "Epoch [1/1], Step [28700/30000], Loss: 4.8605\n",
            "Epoch [1/1], Step [28800/30000], Loss: 5.5641\n",
            "Epoch [1/1], Step [28900/30000], Loss: 5.6392\n",
            "Epoch [1/1], Step [29000/30000], Loss: 5.3375\n",
            "Epoch [1/1], Step [29100/30000], Loss: 5.8501\n",
            "Epoch [1/1], Step [29200/30000], Loss: 4.5961\n",
            "Epoch [1/1], Step [29300/30000], Loss: 5.6852\n",
            "Epoch [1/1], Step [29400/30000], Loss: 4.9193\n",
            "Epoch [1/1], Step [29500/30000], Loss: 4.4738\n",
            "Epoch [1/1], Step [29600/30000], Loss: 5.6956\n",
            "Epoch [1/1], Step [29700/30000], Loss: 4.4233\n",
            "Epoch [1/1], Step [29800/30000], Loss: 4.5883\n",
            "Epoch [1/1], Step [29900/30000], Loss: 5.3362\n",
            "Epoch [1/1], Step [30000/30000], Loss: 4.3942\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3FrFOP9aEtN"
      },
      "source": [
        "# Predict "
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBArQ3oYSw3Y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "outputId": "df38a6b8-fe3b-484c-8da4-2a01240cb19d"
      },
      "source": [
        "images, labels = next(iter(test_ul_dataloader))\n",
        "imshow(images[0]) # torchvision.utils.make_grid(images[0])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noD_ancQtarY"
      },
      "source": [
        "# Setup CSV for predictions export\n",
        "df = pd.DataFrame(columns=['# Id', 'Category'])"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_3icX5sZ2CF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 627
        },
        "outputId": "245fb936-ee8e-42ab-9283-15cacbede116"
      },
      "source": [
        "with torch.no_grad():\n",
        "    i = 0\n",
        "    for data in test_ul_dataloader:\n",
        "        images, labels = data\n",
        "        images = data[0].to(device)[None, :]\n",
        "        images = images.permute(1, 0, 2, 3)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        label_predicted = labels_encoder.inverse_transform([predicted[0]])\n",
        "        prediction = str(label_predicted[0])\n",
        "        df.loc[i] = [i, prediction]\n",
        "        i += 1"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-83-0c480e48ab0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mlabel_predicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-311c98802cb9>\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# img = img / 2 + 0.5     # unnormalize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# npimg = img.numpy()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;31m# plt.imshow(np.transpose(npimg, (1, 2, 0)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, data, **kwargs)\u001b[0m\n\u001b[1;32m   2649\u001b[0m         \u001b[0mfilternorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimlim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimlim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2650\u001b[0m         resample=resample, url=url, **({\"data\": data} if data is not\n\u001b[0;32m-> 2651\u001b[0;31m         None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2652\u001b[0m     \u001b[0msci\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__ret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2653\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m__ret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1563\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1565\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1567\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    356\u001b[0m                 \u001b[0;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    356\u001b[0m                 \u001b[0;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5624\u001b[0m                               resample=resample, **kwargs)\n\u001b[1;32m   5625\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5626\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5627\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5628\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    697\u001b[0m                 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):\n\u001b[1;32m    698\u001b[0m             raise TypeError(\"Invalid shape {} for image data\"\n\u001b[0;32m--> 699\u001b[0;31m                             .format(self._A.shape))\n\u001b[0m\u001b[1;32m    700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Invalid shape (1, 56, 56) for image data"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssnB3f2W5wVS",
        "outputId": "dd50b7b7-7a79-4895-f725-f167529a586a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        }
      },
      "source": [
        ""
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th># Id</th>\n",
              "      <th>Category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [# Id, Category]\n",
              "Index: []"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrgwPKD_p1Vt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "outputId": "1ba549ce-ff7e-45eb-f242-59739cc36d1a"
      },
      "source": [
        "# Export CSV for Kaggle\n",
        "from datetime import datetime\n",
        "filename = 'kaggle_g19_{}.csv'.format(datetime.now())\n",
        "df.to_csv(filename, sep=',', index=False)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-78-9452c9ac7398>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Export CSV for Kaggle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Category'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Category'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Int64\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'kaggle_g19_{}.csv'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   5546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5547\u001b[0m             \u001b[0;31m# else, only a single dtype is given\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5548\u001b[0;31m             \u001b[0mnew_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5549\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"astype\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    602\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"raise\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m     ) -> \"BlockManager\":\n\u001b[0;32m--> 604\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"astype\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    605\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m     def convert(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[1;32m    407\u001b[0m                 \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m                 \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    593\u001b[0m             \u001b[0mvals1d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mastype_nansafe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvals1d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    596\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m                 \u001b[0;31m# e.g. astype_nansafe can fail on object-dtype of strings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/dtypes/cast.py\u001b[0m in \u001b[0;36mastype_nansafe\u001b[0;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[1;32m    917\u001b[0m     \u001b[0;31m# dispatch on extension dtype if needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_extension_array_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 919\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstruct_array_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_from_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    920\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    921\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/arrays/integer.py\u001b[0m in \u001b[0;36m_from_sequence\u001b[0;34m(cls, scalars, dtype, copy)\u001b[0m\n\u001b[1;32m    376\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_from_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscalars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"IntegerArray\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0minteger_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscalars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/arrays/integer.py\u001b[0m in \u001b[0;36minteger_array\u001b[0;34m(values, dtype, copy)\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0mTypeError\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mincompatible\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \"\"\"\n\u001b[0;32m--> 160\u001b[0;31m     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoerce_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mIntegerArray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/arrays/integer.py\u001b[0m in \u001b[0;36mcoerce_to_array\u001b[0;34m(values, dtype, mask, copy)\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0;34m\"mixed-integer-float\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         ]:\n\u001b[0;32m--> 244\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{values.dtype} cannot be converted to an IntegerDtype\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_bool_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_integer_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: object cannot be converted to an IntegerDtype"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpTkvmx3ubFV"
      },
      "source": [
        ""
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wdI6FpAu7zs"
      },
      "source": [
        ""
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBwQPCZ2wjJ5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}